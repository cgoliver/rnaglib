{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-31T13:57:08.073076Z",
     "start_time": "2024-05-31T13:57:06.744896Z"
    }
   },
   "source": [
    "from collections import Counter\n",
    "from networkx import get_node_attributes\n",
    "import shutil\n",
    "import torch\n",
    "from torch.nn import Linear\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch_geometric.nn import GCNConv, GraphConv, SAGEConv\n",
    "import wandb"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-31T13:57:08.930685Z",
     "start_time": "2024-05-31T13:57:08.075048Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from rnaglib.tasks import BenchmarkLigandBindingSiteDetection, BindingSiteDetection\n",
    "from rnaglib.representations import GraphRepresentation\n",
    "from rnaglib.data_loading import Collater"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index file not found at /home/vmallet/.rnaglib/indexes/rnaglib-nr-1.0.0.json. Run rnaglib_index\n",
      "Index file not found at /home/vmallet/.rnaglib/indexes/rnaglib-nr-1.0.0.json. Run rnaglib_index\n",
      "Index file not found at /home/vmallet/.rnaglib/indexes/rnaglib-nr-1.0.0.json. Run rnaglib_index\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-31T13:57:10.019665Z",
     "start_time": "2024-05-31T13:57:08.931686Z"
    }
   },
   "source": [
    "shutil.rmtree('test_fri')\n",
    "ta = BenchmarkLigandBindingSiteDetection(root='test_fri')\n",
    "ta.dataset.add_representation(GraphRepresentation(framework='pyg'))\n",
    "# get_node_attributes(ta.dataset[0]['rna'], 'nt_code')"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database was found and not overwritten\n",
      ">>> Computing splits...\n",
      ">>> Saving dataset.\n",
      ">>> Done\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-31T13:57:11.301249Z",
     "start_time": "2024-05-31T13:57:10.020882Z"
    }
   },
   "source": [
    "train_ind, val_ind, test_ind = ta.split()\n",
    "train_set = ta.dataset.subset(train_ind)\n",
    "val_set = ta.dataset.subset(val_ind)\n",
    "test_set = ta.dataset.subset(test_ind)\n",
    "\n",
    "collater = Collater(train_set)\n",
    "train_loader = DataLoader(train_set, batch_size=8, shuffle=True, collate_fn=collater)\n",
    "val_loader = DataLoader(val_set, batch_size=2, shuffle=False, collate_fn=collater)\n",
    "test_loader = DataLoader(test_set, batch_size=2, shuffle=False, collate_fn=collater)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Loading splits...\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-31T13:57:11.321530Z",
     "start_time": "2024-05-31T13:57:11.303281Z"
    }
   },
   "source": [
    "for batch in train_loader:\n",
    "    print(batch)\n",
    "    graph = batch['graph']\n",
    "    print(f'Batch node features shape: \\t{graph.x.shape}')\n",
    "    print(f'Batch edge index shape: \\t{graph.edge_index.shape}')\n",
    "    print(f'Batch labels shape: \\t\\t{graph.y.shape}')\n",
    "    break"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'graph': DataBatch(x=[357, 4], edge_index=[2, 958], edge_attr=[958], y=[357, 1], batch=[357], ptr=[9]), 'rna': [<networkx.classes.digraph.DiGraph object at 0x7f22c8915b80>, <networkx.classes.digraph.DiGraph object at 0x7f22c89158b0>, <networkx.classes.digraph.DiGraph object at 0x7f22c89158e0>, <networkx.classes.digraph.DiGraph object at 0x7f231042da60>, <networkx.classes.digraph.DiGraph object at 0x7f22c8915ac0>, <networkx.classes.digraph.DiGraph object at 0x7f22cad30580>, <networkx.classes.digraph.DiGraph object at 0x7f22c9f98160>, <networkx.classes.digraph.DiGraph object at 0x7f231042d8e0>]}\n",
      "Batch node features shape: \ttorch.Size([357, 4])\n",
      "Batch edge index shape: \ttorch.Size([2, 958])\n",
      "Batch labels shape: \t\ttorch.Size([357, 1])\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-31T13:57:11.411552Z",
     "start_time": "2024-05-31T13:57:11.322790Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "# Assuming train_loader is defined and loaded with the dataset\n",
    "def calculate_length_statistics(dataset):\n",
    "    lengths = [data['graph'].x.shape[0] for data in dataset]\n",
    "\n",
    "    max_length = np.max(lengths)\n",
    "    min_length = np.min(lengths)\n",
    "    avg_length = np.mean(lengths)\n",
    "    median_length = np.median(lengths)\n",
    "\n",
    "    return {\"max_length\": max_length,\n",
    "            \"min_length\": min_length,\n",
    "            \"average_length\": avg_length,\n",
    "            \"median_length\": median_length}\n",
    "\n",
    "\n",
    "# Example usage\n",
    "stats = calculate_length_statistics(train_set)\n",
    "print(\"Max Length:\", stats[\"max_length\"])\n",
    "print(\"Min Length:\", stats[\"min_length\"])\n",
    "print(\"Average Length:\", stats[\"average_length\"])\n",
    "print(\"Median Length:\", stats[\"median_length\"])"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Length: 414\n",
      "Min Length: 19\n",
      "Average Length: 53.574074074074076\n",
      "Median Length: 32.5\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-31T13:57:11.502704Z",
     "start_time": "2024-05-31T13:57:11.412690Z"
    }
   },
   "source": [
    "def calculate_fraction_of_ones(loader):\n",
    "    total_ones = 0\n",
    "    total_elements = 0\n",
    "    for batch in loader.dataset:\n",
    "        y = batch['graph'].y\n",
    "        total_ones += (y == 1).sum().item()\n",
    "        total_elements += y.numel()\n",
    "    fraction_of_ones = total_ones / total_elements if total_elements > 0 else 0\n",
    "    return fraction_of_ones\n",
    "\n",
    "\n",
    "# Example usage\n",
    "fraction = calculate_fraction_of_ones(train_loader)\n",
    "print(\"Fraction of ones:\", fraction)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fraction of ones: 0.20255789837538887\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-31T13:57:11.602375Z",
     "start_time": "2024-05-31T13:57:11.503885Z"
    }
   },
   "source": [
    "# Assuming train_loader is defined and loaded with the dataset\n",
    "def count_unique_edge_attrs(train_loader):\n",
    "    unique_edge_attrs = set()\n",
    "    for batch in train_loader:\n",
    "        unique_edge_attrs.update(batch['graph'].edge_attr.tolist())\n",
    "    return len(unique_edge_attrs), unique_edge_attrs\n",
    "\n",
    "\n",
    "# Example usage\n",
    "num_unique_edge_attrs, unique_edge_attrs = count_unique_edge_attrs(train_loader)\n",
    "print(\"Number of unique edge attributes:\", num_unique_edge_attrs)\n",
    "print(\"Unique edge attributes:\", unique_edge_attrs)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique edge attributes: 20\n",
      "Unique edge attributes: {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19}\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-31T13:57:11.606915Z",
     "start_time": "2024-05-31T13:57:11.603557Z"
    }
   },
   "source": [
    "def add_edge_features_to_nodes(data):\n",
    "    # Assuming edge_attr is a tensor of shape [num_edges]\n",
    "    row, col = data.edge_index\n",
    "    edge_features = data.edge_attr\n",
    "\n",
    "    # Add edge features to the corresponding node features\n",
    "    # Here we are adding a new dimension to edge_features to match the dimensions\n",
    "    data.x[row] += edge_features.view(-1, 1)\n",
    "    data.x[col] += edge_features.view(-1, 1)\n",
    "    return data"
   ],
   "outputs": [],
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-31T13:57:17.980113Z",
     "start_time": "2024-05-31T13:57:11.607962Z"
    }
   },
   "source": [
    "wandb.init(project=\"gcn-node-classification\", config={\n",
    "    \"learning_rate\": 0.0001,\n",
    "    \"epochs\": 2000,\n",
    "    \"batch_size\": 1\n",
    "})"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: Currently logged in as: \u001B[33mvincentx15\u001B[0m (\u001B[33matomiclearning\u001B[0m). Use \u001B[1m`wandb login --relogin`\u001B[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Tracking run with wandb version 0.17.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Run data is saved locally in <code>/home/vmallet/projects/rnaglib_folder/rnaglib/tasks/wandb/run-20240531_155713-n2atdrwn</code>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/atomiclearning/gcn-node-classification/runs/n2atdrwn' target=\"_blank\">colorful-smoke-4</a></strong> to <a href='https://wandb.ai/atomiclearning/gcn-node-classification' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View project at <a href='https://wandb.ai/atomiclearning/gcn-node-classification' target=\"_blank\">https://wandb.ai/atomiclearning/gcn-node-classification</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run at <a href='https://wandb.ai/atomiclearning/gcn-node-classification/runs/n2atdrwn' target=\"_blank\">https://wandb.ai/atomiclearning/gcn-node-classification/runs/n2atdrwn</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/atomiclearning/gcn-node-classification/runs/n2atdrwn?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7f22c76947f0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-31T13:57:18.041507Z",
     "start_time": "2024-05-31T13:57:17.981704Z"
    }
   },
   "source": [
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, num_node_features, num_classes):\n",
    "        super(GCN, self).__init__()\n",
    "        self.conv1 = GraphConv(num_node_features, 16)\n",
    "        #self.conv2 = GCNConv(16, 32) \n",
    "        #self.conv3 = GCNConv(32, 16) \n",
    "        self.conv4 = GraphConv(16, num_classes)\n",
    "\n",
    "    def forward(self, data):\n",
    "        data = add_edge_features_to_nodes(data)\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        #x = self.conv2(x, edge_index)\n",
    "        #x = F.relu(x)\n",
    "        #x = self.conv3(x, edge_index)\n",
    "        #x = F.relu(x)\n",
    "        x = self.conv4(x, edge_index)\n",
    "\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "\n",
    "num_classes = 2\n",
    "model = GCN(train_set.input_dim, num_classes)"
   ],
   "outputs": [],
   "execution_count": 11
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-31T13:57:18.137827Z",
     "start_time": "2024-05-31T13:57:18.042896Z"
    }
   },
   "source": [
    "all_labels = []\n",
    "for batch in train_loader:\n",
    "    batch_labels = batch['graph'].y\n",
    "    all_labels.extend(torch.flatten(batch_labels).tolist())\n",
    "class_counts = Counter(all_labels)\n",
    "total_samples = len(all_labels)\n",
    "class_weights = {cls: total_samples / count for cls, count in class_counts.items()}\n",
    "weights = torch.tensor([class_weights[i] for i in range(num_classes)])\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "criterion = torch.nn.CrossEntropyLoss(weight=weights)"
   ],
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-31T13:57:18.144193Z",
     "start_time": "2024-05-31T13:57:18.138926Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def train():\n",
    "    model.train()\n",
    "    for batch in train_loader:\n",
    "        graph = batch['graph']\n",
    "        graph = graph.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        out = model(graph)\n",
    "        loss = criterion(out, torch.flatten(graph.y).long())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        wandb.log({\"loss\": loss.item()})\n",
    "\n",
    "\n",
    "def test(loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    for batch in loader:\n",
    "        graph = batch['graph']\n",
    "        graph = graph.to(device)\n",
    "        out = model(graph)\n",
    "        pred = out.argmax(dim=1)\n",
    "        correct += (pred == graph.y).sum().item()\n",
    "    return correct / len(loader.dataset)"
   ],
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-31T13:57:29.315223Z",
     "start_time": "2024-05-31T13:57:18.146916Z"
    }
   },
   "cell_type": "code",
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model = model.to(device)\n",
    "for epoch in range(50):\n",
    "    train()\n",
    "    train_acc = test(train_loader)\n",
    "    val_acc = test(val_loader)\n",
    "    print(f'Epoch: {epoch}, Train Acc: {train_acc:.4f}, Val Acc: {val_acc:.4f}')\n",
    "    wandb.log({\"train_acc\": train_acc, \"val_acc\": val_acc})"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Train Acc: 15110.5370, Val Acc: 914.8333\n",
      "Epoch: 1, Train Acc: 16308.7222, Val Acc: 895.1667\n",
      "Epoch: 2, Train Acc: 14553.5741, Val Acc: 883.0000\n",
      "Epoch: 3, Train Acc: 14298.7222, Val Acc: 871.0000\n",
      "Epoch: 4, Train Acc: 12514.0000, Val Acc: 872.0000\n",
      "Epoch: 5, Train Acc: 11732.5556, Val Acc: 871.5000\n",
      "Epoch: 6, Train Acc: 12029.8519, Val Acc: 878.6667\n",
      "Epoch: 7, Train Acc: 11670.6667, Val Acc: 878.6667\n",
      "Epoch: 8, Train Acc: 11933.2407, Val Acc: 878.6667\n",
      "Epoch: 9, Train Acc: 12664.5926, Val Acc: 874.8333\n",
      "Epoch: 10, Train Acc: 11805.6296, Val Acc: 875.3333\n",
      "Epoch: 11, Train Acc: 12056.5926, Val Acc: 880.6667\n",
      "Epoch: 12, Train Acc: 11490.7222, Val Acc: 880.6667\n",
      "Epoch: 13, Train Acc: 12331.4259, Val Acc: 881.1667\n",
      "Epoch: 14, Train Acc: 11793.7963, Val Acc: 881.1667\n",
      "Epoch: 15, Train Acc: 13052.3519, Val Acc: 881.1667\n",
      "Epoch: 16, Train Acc: 11532.9815, Val Acc: 877.3333\n",
      "Epoch: 17, Train Acc: 13242.4630, Val Acc: 877.3333\n",
      "Epoch: 18, Train Acc: 12451.1481, Val Acc: 877.3333\n",
      "Epoch: 19, Train Acc: 11223.0000, Val Acc: 877.3333\n",
      "Epoch: 20, Train Acc: 12885.0556, Val Acc: 881.1667\n",
      "Epoch: 21, Train Acc: 13386.2963, Val Acc: 881.1667\n",
      "Epoch: 22, Train Acc: 11566.8519, Val Acc: 877.3333\n",
      "Epoch: 23, Train Acc: 11959.2963, Val Acc: 881.1667\n",
      "Epoch: 24, Train Acc: 11473.0370, Val Acc: 877.3333\n",
      "Epoch: 25, Train Acc: 12192.2407, Val Acc: 877.8333\n",
      "Epoch: 26, Train Acc: 13121.9074, Val Acc: 877.8333\n",
      "Epoch: 27, Train Acc: 11961.3148, Val Acc: 877.8333\n",
      "Epoch: 28, Train Acc: 12812.7407, Val Acc: 877.8333\n",
      "Epoch: 29, Train Acc: 12089.6852, Val Acc: 877.8333\n",
      "Epoch: 30, Train Acc: 13160.9630, Val Acc: 881.6667\n",
      "Epoch: 31, Train Acc: 12300.9259, Val Acc: 877.8333\n",
      "Epoch: 32, Train Acc: 12432.4074, Val Acc: 877.8333\n",
      "Epoch: 33, Train Acc: 11913.7593, Val Acc: 877.8333\n",
      "Epoch: 34, Train Acc: 12395.1852, Val Acc: 877.8333\n",
      "Epoch: 35, Train Acc: 11926.2593, Val Acc: 877.8333\n",
      "Epoch: 36, Train Acc: 12713.2778, Val Acc: 877.8333\n",
      "Epoch: 37, Train Acc: 11928.6111, Val Acc: 874.0000\n",
      "Epoch: 38, Train Acc: 11901.4259, Val Acc: 877.8333\n",
      "Epoch: 39, Train Acc: 14305.4074, Val Acc: 877.8333\n",
      "Epoch: 40, Train Acc: 12835.9259, Val Acc: 874.0000\n",
      "Epoch: 41, Train Acc: 11999.2407, Val Acc: 874.0000\n",
      "Epoch: 42, Train Acc: 11861.9074, Val Acc: 874.0000\n",
      "Epoch: 43, Train Acc: 11683.8704, Val Acc: 877.8333\n",
      "Epoch: 44, Train Acc: 13137.8333, Val Acc: 881.6667\n",
      "Epoch: 45, Train Acc: 12118.9444, Val Acc: 881.6667\n",
      "Epoch: 46, Train Acc: 12152.7407, Val Acc: 881.6667\n",
      "Epoch: 47, Train Acc: 12653.3148, Val Acc: 881.6667\n",
      "Epoch: 48, Train Acc: 12658.6852, Val Acc: 881.6667\n",
      "Epoch: 49, Train Acc: 11698.2778, Val Acc: 881.6667\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-31T13:57:29.354922Z",
     "start_time": "2024-05-31T13:57:29.316782Z"
    }
   },
   "source": [
    "test_acc = test(test_loader)\n",
    "print(f'Test Accuracy: {test_acc:.4f}')\n",
    "wandb.log({\"test_acc\": test_acc})"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 1212.2778\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-31T13:57:29.402809Z",
     "start_time": "2024-05-31T13:57:29.356246Z"
    }
   },
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
    "\n",
    "\n",
    "def get_predictions(loader):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    for batch in loader:\n",
    "        graph = batch['graph']\n",
    "        graph = graph.to(device)\n",
    "        out = model(graph)\n",
    "        preds = out.argmax(dim=1)\n",
    "        all_preds.extend(preds.tolist())\n",
    "        all_labels.extend(torch.flatten(graph.y).tolist())\n",
    "    return all_preds, all_labels\n",
    "\n",
    "\n",
    "def calculate_metrics(loader):\n",
    "    preds, labels = get_predictions(loader)\n",
    "    accuracy = accuracy_score(labels, preds)\n",
    "    f1 = f1_score(labels, preds)\n",
    "    auc = roc_auc_score(labels, preds)\n",
    "    return accuracy, f1, auc\n",
    "\n",
    "\n",
    "test_accuracy, test_f1, test_auc = calculate_metrics(test_loader)\n",
    "print(f'Test Accuracy: {test_accuracy:.4f}, Test F1 Score: {test_f1:.4f}, Test AUC: {test_auc:.4f}')\n",
    "wandb.log({\"test_accuracy\": test_accuracy, \"test_f1\": test_f1, \"test_auc\": test_auc})"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.4763, Test F1 Score: 0.3600, Test AUC: 0.4958\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-31T13:57:34.200884Z",
     "start_time": "2024-05-31T13:57:29.404036Z"
    }
   },
   "source": [
    "wandb.finish()\n"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VBox(children=(Label(value='0.002 MB of 0.002 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c0f3f0408dcb411dbec6d2fb1a2502cf"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>loss</td><td>█▆▃▄▃▄▃▃▂▃▃▃▃▃▂▁▃▃▁▁▂▁▂▂▂▁▂▂▂▂▁▂▂▂▂▂▃▁▂▁</td></tr><tr><td>test_acc</td><td>▁</td></tr><tr><td>test_accuracy</td><td>▁</td></tr><tr><td>test_auc</td><td>▁</td></tr><tr><td>test_f1</td><td>▁</td></tr><tr><td>train_acc</td><td>▆█▅▅▁▂▁▂▁▂▁▂▃▁▄▂▃▄▁▂▂▃▂▃▃▂▂▂▂▃▂▂▃▂▂▁▂▂▃▁</td></tr><tr><td>val_acc</td><td>█▅▃▁▁▂▂▂▂▃▃▃▃▂▂▂▃▃▂▃▂▂▂▂▃▂▂▂▂▂▁▂▁▁▁▂▃▃▃▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>loss</td><td>1.06153</td></tr><tr><td>test_acc</td><td>1212.27778</td></tr><tr><td>test_accuracy</td><td>0.47627</td></tr><tr><td>test_auc</td><td>0.49581</td></tr><tr><td>test_f1</td><td>0.36</td></tr><tr><td>train_acc</td><td>11698.27778</td></tr><tr><td>val_acc</td><td>881.66667</td></tr></table><br/></div></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">colorful-smoke-4</strong> at: <a href='https://wandb.ai/atomiclearning/gcn-node-classification/runs/n2atdrwn' target=\"_blank\">https://wandb.ai/atomiclearning/gcn-node-classification/runs/n2atdrwn</a><br/> View project at: <a href='https://wandb.ai/atomiclearning/gcn-node-classification' target=\"_blank\">https://wandb.ai/atomiclearning/gcn-node-classification</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Find logs at: <code>./wandb/run-20240531_155713-n2atdrwn/logs</code>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 17
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
